{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'titanic_tpot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtitanic_tpot\u001b[49m\u001b[38;5;241m.\u001b[39mipynb\n",
      "\u001b[0;31mNameError\u001b[0m: name 'titanic_tpot' is not defined"
     ]
    }
   ],
   "source": [
    "train = 'train.csv'\n",
    "test = 'test.csv'\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(train, index_col='PassengerId')\n",
    "df_test = pd.read_csv(test, index_col='PassengerId')\n",
    "drop_columns = ['Ticket']\n",
    "passthrough_columns=['Pclass', 'SibSp', 'Parch']\n",
    "target_column = ['Survived']\n",
    "\n",
    "text_columns_manquant = ['Cabin']  \n",
    "text_columns_sans_manquant = ['Name']\n",
    "\n",
    "numeric_columns_manquant =['Age', 'Fare']\n",
    "cat_manquant = ['Embarked']\n",
    "cat_sans_manquant = ['Sex']\n",
    "\n",
    "X = df.drop('Survived', axis=1)\n",
    "y = df['Survived']\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_transformer \n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "#pipeline pour le preprocesing des colonnes catégorielles avec des valeurs manquantes\n",
    "cat_manquant_pipeline = make_pipeline(SimpleImputer(strategy='most_frequent'), OneHotEncoder(handle_unknown='ignore'))\n",
    "\n",
    "\n",
    "#fonction transformer custom : preprocess de cabin\n",
    "def extract_cabin_letter(df):\n",
    "    return pd.DataFrame(df.str[0])\n",
    "\n",
    "FunctionTransformer(extract_cabin_letter)\n",
    "\n",
    "#pipeline pour le preprocesing de cabin\n",
    "\n",
    "preprocessor_cabin = make_pipeline(\n",
    "    FunctionTransformer(extract_cabin_letter),\n",
    "    SimpleImputer(strategy='constant', fill_value='missing'),\n",
    "    OneHotEncoder(handle_unknown='ignore')\n",
    ")\n",
    "\n",
    "#make_column_transformer: permet de faire un preprocessing spécifique pour chaque colonne\n",
    "preprocessor = make_column_transformer(\n",
    "    (OneHotEncoder(handle_unknown='ignore'), cat_sans_manquant),\n",
    "    (cat_manquant_pipeline, cat_manquant),\n",
    "    (SimpleImputer(strategy='median'), numeric_columns_manquant),\n",
    "    (CountVectorizer(), 'Name'),\n",
    "    (preprocessor_cabin, 'Cabin'),\n",
    "    ('passthrough', passthrough_columns),\n",
    "    ('drop', drop_columns),\n",
    ")\n",
    "# data leakage + data cleaning\n",
    "\n",
    "x_clean = preprocessor.fit_transform(X, y)\n",
    "#cross validation\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cross_val_fold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "import tpot\n",
    "from tpot import TPOTClassifier\n",
    "\n",
    "automl = TPOTClassifier(generations=10,\n",
    "                        population_size=100,\n",
    "                        scoring='accuracy',\n",
    "                        cv=5,\n",
    "                        config_dict='TPOT sparse',\n",
    "                        verbosity=2,\n",
    "                        random_state=0,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "automl.fit(x_clean, y)\n",
    "#export automl .py\n",
    "\n",
    "automl.export('tpot_titanic_pipeline.py')\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(bootstrap=True, criterion=\"entropy\", max_features=0.8, min_samples_leaf=5, min_samples_split=12, n_estimators=100)\n",
    "\n",
    "rf_pipeline = make_pipeline(preprocessor, rf)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "cross_val_score(rf_pipeline, X, y, cv=5, scoring='accuracy').mean()\n",
    "\n",
    "#mmmml  tgggrgffezfesdnj "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
